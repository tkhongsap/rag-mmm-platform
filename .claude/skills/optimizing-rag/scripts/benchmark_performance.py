#!/usr/bin/env python3
"""
Benchmark RAG retrieval performance.

Measures:
- Retrieval latency (p50, p95, p99)
- Throughput (queries/second)
- Memory usage

Usage:
    python benchmark_performance.py --num-queries 100
"""

import argparse
import time
import statistics
from typing import List
import sys


def measure_latencies(num_queries: int, simulate: bool = True) -> List[float]:
    """
    Measure retrieval latencies.

    In actual use, replace simulation with real retrieval calls.
    """
    import random
    latencies = []

    for i in range(num_queries):
        start = time.time()

        if simulate:
            # Simulate retrieval (50-200ms with some outliers)
            if random.random() < 0.05:  # 5% slow queries
                time.sleep(random.uniform(0.3, 0.8))
            else:
                time.sleep(random.uniform(0.05, 0.2))
        else:
            # Replace with actual retrieval:
            # results = retriever.retrieve(f"query_{i}")
            pass

        latency = (time.time() - start) * 1000  # Convert to ms
        latencies.append(latency)

        if (i + 1) % 10 == 0:
            print(f"Processed {i + 1}/{num_queries} queries...", file=sys.stderr)

    return latencies


def calculate_percentiles(latencies: List[float]) -> dict:
    """Calculate percentile statistics."""
    sorted_latencies = sorted(latencies)
    n = len(sorted_latencies)

    return {
        "p50": sorted_latencies[int(n * 0.50)],
        "p90": sorted_latencies[int(n * 0.90)],
        "p95": sorted_latencies[int(n * 0.95)],
        "p99": sorted_latencies[int(n * 0.99)],
        "min": min(sorted_latencies),
        "max": max(sorted_latencies),
        "mean": statistics.mean(sorted_latencies),
        "median": statistics.median(sorted_latencies),
    }


def format_latency(ms: float) -> str:
    """Format latency with color coding."""
    if ms < 100:
        return f"{ms:.1f}ms (excellent)"
    elif ms < 500:
        return f"{ms:.1f}ms (good)"
    elif ms < 1000:
        return f"{ms:.1f}ms (acceptable)"
    else:
        return f"{ms:.1f}ms (needs optimization)"


def main():
    parser = argparse.ArgumentParser(description="Benchmark RAG retrieval performance")
    parser.add_argument("--num-queries", type=int, default=100, help="Number of queries to benchmark")
    parser.add_argument("--simulate", action="store_true", default=True, help="Use simulated retrieval (for demo)")

    args = parser.parse_args()

    print("=" * 60)
    print("RAG Performance Benchmark")
    print("=" * 60)
    print(f"\nRunning {args.num_queries} queries...")
    print()

    # Measure latencies
    start_time = time.time()
    latencies = measure_latencies(args.num_queries, args.simulate)
    total_time = time.time() - start_time

    # Calculate statistics
    percentiles = calculate_percentiles(latencies)
    throughput = args.num_queries / total_time

    # Print results
    print("\n" + "=" * 60)
    print("Latency Percentiles")
    print("=" * 60)
    print(f"  p50 (median): {format_latency(percentiles['p50'])}")
    print(f"  p90:          {format_latency(percentiles['p90'])}")
    print(f"  p95:          {format_latency(percentiles['p95'])}")
    print(f"  p99:          {format_latency(percentiles['p99'])}")
    print(f"  min:          {percentiles['min']:.1f}ms")
    print(f"  max:          {percentiles['max']:.1f}ms")
    print(f"  mean:         {percentiles['mean']:.1f}ms")

    print("\n" + "=" * 60)
    print("Throughput")
    print("=" * 60)
    print(f"  Queries/second: {throughput:.2f}")
    print(f"  Total time:     {total_time:.2f}s")

    print("\n" + "=" * 60)
    print("Performance Recommendations")
    print("=" * 60)

    # Provide recommendations
    if percentiles['p95'] > 1000:
        print("  ⚠️  p95 latency > 1s - Critical optimization needed")
        print("     - Add metadata pre-filtering")
        print("     - Reduce top_k")
        print("     - Use BM25 for simple queries")
    elif percentiles['p95'] > 500:
        print("  ⚠️  p95 latency > 500ms - Optimization recommended")
        print("     - Consider hybrid search")
        print("     - Enable async operations")
        print("     - Optimize chunk size")
    else:
        print("  ✓ Latency within acceptable range")

    if throughput < 5:
        print(f"  ⚠️  Low throughput ({throughput:.1f} q/s)")
        print("     - Enable parallel retrieval")
        print("     - Use local embeddings")
        print("     - Implement caching")
    else:
        print(f"  ✓ Good throughput ({throughput:.1f} queries/second)")

    print("=" * 60)

    return 0


if __name__ == "__main__":
    sys.exit(main())
